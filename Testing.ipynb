{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gnKyNhy4Sw0P"
      },
      "source": [
        "In this version,\n",
        "- Testing pipline of the selection mechanism\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "X0WJjFZ_mhqu",
        "outputId": "478861fb-664f-48a2-c73a-75e270b07b17"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(\"Tensorflow version: \",tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Checking if cuda is there.\n",
        "print(\"Cuda Availability: \", tf.test.is_built_with_cuda())\n",
        "\n",
        "# Checking GPU is available or not.\n",
        "print(\"GPU  Availability: \", tf.test.is_gpu_available())\n",
        "\n",
        "# Check nos of GPUS\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "m_dPbml8d8FP"
      },
      "source": [
        "# Data Downloading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-lJiLRCeT1-",
        "outputId": "4fe0d3a1-1601-4748-b7d0-43a0325910f4"
      },
      "outputs": [],
      "source": [
        "# choose the dataset version and paths\n",
        "# 'modelnet40v1' or 'modelnet40v2' or 'shaded_modelnet40v2'\n",
        "#(here modelnet40v1)\n",
        "##########################\n",
        "dataset_version= 'modelnet40v1' \n",
        "dataset_test= './data/modelnet40v1_test'\n",
        "\n",
        "#dataset_version= 'modelnet40v2'\n",
        "#dataset_test = './data/modelnet40v2_test'\n",
        "\n",
        "#dataset_version= 'shaded_modelnet40v2'\n",
        "#dataset_test = './data/modelnet40v2_test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# spicify the img size (here 224*224)\n",
        "Img_Size= 224 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# spicify selection mechanism\n",
        "# the Most Similar View (MSV) or Most Dissimilar View (MDV)\n",
        "# (here 'MSV')\n",
        "#####################################\n",
        "\n",
        "selection_mechanism = 'MSV'\n",
        "#selection_mechanism = 'MDV'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "us_3RIAGebLJ"
      },
      "source": [
        "# Data Processing\n",
        "\n",
        "\n",
        "We've included helper functions that will label images, convert them into arrays, and then finally into a generator that will enable them to be loaded into the model in batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BPK8hfbbecMu"
      },
      "outputs": [],
      "source": [
        "# for training and testing\n",
        "##########################\n",
        "\n",
        "import random #Python Random module is an in-built module of Python which is used to generate random numbers.\n",
        "from random import shuffle #is an inbuilt method of the random module. It is used to shuffle a sequence (list). Shuffling a list of objects means changing the position of the elements of the sequence\n",
        "import cv2 # OpenCV-Python is a library of Python bindings designed to solve computer vision problems.\n",
        "import os # Python OS module provides the facility to establish the interaction between the user and the operating system. It offers many useful OS functions that are used to perform OS-based tasks and get related information about operating system.\n",
        "from tqdm import tqdm # is a library in Python which is used for creating Progress Meters or Progress Bars. tqdm got its name from the Arabic name taqaddum which means 'progress'\n",
        "import matplotlib.pyplot as plt #Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python. Matplotlib makes easy things easy and hard things possible. Create publication quality plots. Make interactive figures that can zoom, pan, update. Customize visual style and layout.\n",
        "import numpy as np #NumPy (Numerical Python) is an open-source library for the Python programming language. It is used for scientific computing and working with arrays.\n",
        "from tensorflow.python.keras.utils.data_utils import Sequence #Keras and TensorFlow are open source Python libraries for working with neural networks, creating machine learning models and performing deep learning\n",
        "# keras.utils This package provides utilities for Keras, such as modified callbacks, genereators, etc.\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LWhHWkkfVaAI"
      },
      "outputs": [],
      "source": [
        "# for training and testing\n",
        "##########################\n",
        "\n",
        "#For shuffling or any thing random\n",
        "import random #Python Random module is an in-built module of Python which is used to generate random numbers.\n",
        "from random import shuffle #is an inbuilt method of the random module. It is used to shuffle a sequence (list). Shuffling a list of objects means changing the position of the elements of the sequence\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdSqKQdR5pVS",
        "outputId": "435b9851-0094-4468-9e4e-5ef7062ba3b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of views is 20\n"
          ]
        }
      ],
      "source": [
        "# for training and testing\n",
        "##########################\n",
        "\n",
        "global num_views\n",
        "\n",
        "if dataset_version == 'modelnet40v1' or dataset_version == 'original_modelnet40v1':\n",
        "    num_views = 12\n",
        "elif dataset_version == 'modelnet40v2':\n",
        "    num_views = 20\n",
        "\n",
        "print (\"number of views is \" + str(num_views))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wFhWO9hL3Q2L"
      },
      "outputs": [],
      "source": [
        "# for training and testing\n",
        "##########################\n",
        "\n",
        "\n",
        "def extract_View_No(img): # function to extract the view no\n",
        "  ## Helper for process_data\n",
        "  ViewNo =img[-6:-4] #take the last 2 characters from the img name before the \".png\"\n",
        "  if ViewNo == '01': return 1\n",
        "  elif ViewNo == '02': return 2\n",
        "  elif ViewNo == '03': return 3\n",
        "  elif ViewNo == '04': return 4\n",
        "  elif ViewNo == '05': return 5\n",
        "  elif ViewNo == '06': return 6\n",
        "  elif ViewNo == '07': return 7\n",
        "  elif ViewNo == '08': return 8\n",
        "  elif ViewNo == '09': return 9\n",
        "  elif ViewNo == '10': return 10\n",
        "  elif ViewNo == '11': return 11\n",
        "  elif ViewNo == '12': return 12\n",
        "  elif ViewNo == '13': return 13\n",
        "  elif ViewNo == '14': return 14\n",
        "  elif ViewNo == '15': return 15\n",
        "  elif ViewNo == '16': return 16\n",
        "  elif ViewNo == '17': return 17\n",
        "  elif ViewNo == '18': return 18\n",
        "  elif ViewNo == '19': return 19\n",
        "  elif ViewNo == '20': return 20\n",
        "  #print(ViewNo)\n",
        "\n",
        "\n",
        "def label_image_encoder(img): # function to label image\n",
        "  ## Helper for process_data\n",
        "  label = img.split('_')[0] # from the image name, take the part before \"_\" and consider it as label #split() method is a beneficial tool for manipulating strings. It returns a list of strings after the main string is separated by a delimiter.\n",
        "  if label == 'airplane': return 0 # encode airplane label as 0\n",
        "  elif label == 'bathtub': return 1 # encode bathtub label as 1\n",
        "  elif label == 'bed': return 2 # encode bed label as 2\n",
        "  elif label == 'bench': return 3 # encode bench label as 3\n",
        "  elif label == 'bookshelf': return 4 # encode bookshelf label as 4\n",
        "  elif label == 'bottle': return 5 # encode bottle label as 5\n",
        "  elif label == 'bowl': return 6 # encode bowl label as 6\n",
        "  elif label == 'car': return 7 # encode car label as 7\n",
        "  elif label == 'chair': return 8 # encode chair label as 8\n",
        "  elif label == 'cone': return 9 # encode cone label as 9\n",
        "  elif label == 'cup': return 10 # encode cup label as 10\n",
        "  elif label == 'curtain': return 11 # encode curtain label as 11\n",
        "  elif label == 'desk': return 12 # encode desk label as 12\n",
        "  elif label == 'door': return 13 # encode door label as 13\n",
        "  elif label == 'dresser': return 14 # encode dresser label as 14\n",
        "  elif label == 'flower': return 15 # encode floer_pot label as 15\n",
        "  elif label == 'glass': return 16 # encode glass_box label as 16\n",
        "  elif label == 'guitar': return 17 # encode guitar label as 17\n",
        "  elif label == 'keyboard': return 18 # encode keyboard label as 18\n",
        "  elif label == 'lamp': return 19 # encode lamp label as 19\n",
        "  elif label == 'laptop': return 20 # encode laptop label as 20\n",
        "  elif label == 'mantel': return 21 # encode mantel label as 21\n",
        "  elif label == 'monitor': return 22 # encode monitor label as 22\n",
        "  elif label == 'night': return 23 # encode night_stand label as 23\n",
        "  elif label == 'person': return 24 # encode person label as 24\n",
        "  elif label == 'piano': return 25 # encode piano label as 25\n",
        "  elif label == 'plant': return 26 # encode plant label as 26\n",
        "  elif label == 'radio': return 27 # encode radio label as 27\n",
        "  elif label == 'range': return 28 # encode range_hood label as 28\n",
        "  elif label == 'sink': return 29 # encode sink label as 29\n",
        "  elif label == 'sofa': return 30 # encode sofa label as 30\n",
        "  elif label == 'stairs': return 31 # encode stairs label as 31\n",
        "  elif label == 'stool': return 32 # encode stool label as 32\n",
        "  elif label == 'table': return 33 # encode table label as 33\n",
        "  elif label == 'tent': return 34 # encode tent label as 34\n",
        "  elif label == 'toilet': return 35 # encode toilet label as 35\n",
        "  elif label == 'tv': return 36 # encode tv_stand label as 36\n",
        "  elif label == 'vase': return 37 # encode vase label as 37\n",
        "  elif label == 'wardrobe': return 38 # encode wardrobe label as 38\n",
        "  elif label == 'xbox': return 39 # encode xbox label as 39\n",
        "\n",
        "\n",
        "def process_data(image_list, DATA_FOLDER, IMG_SIZE): # function that take the images, the data folder name, and the wanted image size, and retun the list of images as arrays with there labels and paths\n",
        "  ## Helper for manual_pre_process\n",
        "  ## Creates an array of images, labels, and file path\n",
        "  data_df = [] #[] is a list: A multible collection of values, here define new array\n",
        "  for img in tqdm(image_list): # tqdm . It will display a progress bar of the for loop, for each image in image_list do the following\n",
        "    path = os.path.join(DATA_FOLDER, img) # concatenates various path components with exactly one directory separator ('/'), concatenate DATA_FOLDER path then / then the image name to create an image's path\n",
        "    ViewNo = extract_View_No(img) # extract the view no\n",
        "    label = label_image_encoder(img) # use the above function to encode the image's label\n",
        "    img = cv2.imread(path, cv2.IMREAD_COLOR) # cv2. imread() method loads an image from the specified file. IMREAD_COLOR reads the image with RGB colors but no transparency channel, load image from its path\n",
        "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) # Resizing the image img, by only change the width=IMG_SIZE and height=IMG_SIZE of the image, this step to make all image with the same size\n",
        "    #data_df.append([np.array(img), np.array(label), path]) #Append in Python is a pre-defined method used to add a single item to certain collection types. so, append the list data_df by adding sum-list with 3 element for each image [np.array(img)=image as array, np.array(label)=image's label as 0 or 1, path=image's path]it\n",
        "    data_df.append([np.array(img), np.array(label), ViewNo, path]) #Append in Python is a pre-defined method used to add a single item to certain collection types. so, append the list data_df by adding sum-list with 3 element for each image [np.array(img)=image as array, np.array(label)=image's label as 0 or 1, path=image's path]it\n",
        "  \n",
        "  return data_df # return the data_df list after process it\n",
        "\n",
        "\n",
        "def manual_pre_process(dir, IMG_SIZE):\n",
        "  '''\n",
        "  Creates an array of images, labels, and files from a directory of image files\n",
        "\n",
        "  Args:\n",
        "    dir: string, folder name\n",
        "    IMG_SIZE: int, image height and width\n",
        "\n",
        "  Returns\n",
        "    X: (n x IMG_SIZE x IMG_SIZE) numpy array of images\n",
        "    y: (n,) numpy array of labels\n",
        "    files: (n,) numpy array of files\n",
        "\n",
        "  '''\n",
        "  image_lst = sorted(os.listdir(dir)) # get the list of all files and directories in the specified directory \"dir\"\n",
        "  data_df = process_data(image_lst, dir, IMG_SIZE) # take the images, the data folder name, and the wanted image size, and retun the list of images after processing as arrays with there labels and paths\n",
        "  X = np.array([i[0] for i in data_df]).reshape(-1, IMG_SIZE, IMG_SIZE, 3) # take the images only (as arrays) from data_df and save them as X (the input images)\n",
        "  y = np.array([i[1] for i in data_df]) # take the labels only from data_df and save them as Y (the actual labels)\n",
        "  ViewNos = np.array([i[2] for i in data_df]) # take the ViewNo only from data_df and save them as ViewNo\n",
        "  files = np.array([i[3] for i in data_df]) # take the images' paths only from data_df and save them as files\n",
        "  return X, y, ViewNos, files # return X=the images(as arrays), y=the actual labels, and files=the images' paths\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i-a6x51er32",
        "outputId": "e7ac0421-9f99-4df3-e46c-9f8b2a4ebd2e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 49360/49360 [01:32<00:00, 534.10it/s] \n"
          ]
        }
      ],
      "source": [
        "# for training and testing\n",
        "##########################\n",
        "\n",
        "# Dictionary\n",
        "class_info = {0: 'airplane',\n",
        "              1: 'bathtub',\n",
        "              2: 'bed',\n",
        "              3: 'bench',\n",
        "              4: 'bookshelf',\n",
        "              5: 'bottle',\n",
        "              6: 'bowl',\n",
        "              7: 'car',\n",
        "              8: 'chair',\n",
        "              9: 'cone',\n",
        "              10: 'cup',\n",
        "              11: 'curtain',\n",
        "              12: 'desk',\n",
        "              13: 'door',\n",
        "              14: 'dresser',\n",
        "              15: 'flower_pot',\n",
        "              16: 'glass_box',\n",
        "              17: 'guitar',\n",
        "              18: 'keyboard',\n",
        "              19: 'lamp',\n",
        "              20: 'laptop',\n",
        "              21: 'mantel',\n",
        "              22: 'monitor',\n",
        "              23: 'night_stand',\n",
        "              24: 'person',\n",
        "              25: 'piano',\n",
        "              26: 'plant',\n",
        "              27: 'radio',\n",
        "              28: 'range_hood',\n",
        "              29: 'sink',\n",
        "              30: 'sofa',\n",
        "              31: 'stairs',\n",
        "              32: 'stool',\n",
        "              33: 'table',\n",
        "              34: 'tent',\n",
        "              35: 'toilet',\n",
        "              36: 'tv_stand',\n",
        "              37: 'vase',\n",
        "              38: 'wardrobe',\n",
        "              39: 'xbox'} # define a dictionary (a key/value mapping) of the labels\n",
        "\n",
        "\n",
        "#X, y, files = manual_pre_process(val_imgs, 224) # call the manual_pre_process function by passing the directory of the dataset and the wanted image size 224*224\n",
        "\n",
        "#X, y, ViewNo, files = manual_pre_process(modelnet40v1_train, 224)\n",
        "\n",
        "\n",
        "#X_train, y_train, ViewNo_train, files_train = manual_pre_process(modelnet40v1_train_subset, 224)\n",
        "X_test, y_test, ViewNo_test, files_test = manual_pre_process(dataset_test, Img_Size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgdHD9n5Vv65",
        "outputId": "6cf16cf2-1abf-4a3c-fdc5-dffb48b88ddd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of testing Samples is\n",
            "49360\n"
          ]
        }
      ],
      "source": [
        "#for testing\n",
        "########################\n",
        "\n",
        "test_NoOfSamples, h, w, channel= X_test.shape\n",
        "\n",
        "print(\"Number of testing Samples is\")\n",
        "print(test_NoOfSamples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "id": "VMclpUg3YZqP",
        "outputId": "0e99dc6f-d1da-4b41-b64f-491679e9d62c"
      },
      "outputs": [],
      "source": [
        "# for testing\n",
        "##########################\n",
        "# Note: spicify the subplot rows and columns based on the number of views\n",
        "##########################\n",
        "\n",
        "\n",
        "# show the (12 or 20 views) of one object samples before feature extraction\n",
        "plt.figure(figsize=(15, 15)) # create a fig of size 15*15\n",
        "\n",
        "for i in range(0,num_views):\n",
        " img = X_test[i] #take sample image\n",
        " label = y_test[i] #take the label of the sample image\n",
        " viewNo= ViewNo_test[i]\n",
        " path = files_test[i] #take the path of the sample image\n",
        "\n",
        " ax = plt.subplot(4, 5, i +1) # for 20 views\n",
        " #sax = plt.subplot(3, 4, i +1) # for 12 views\n",
        " plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) # show the img in the plot\n",
        " plt.axis('off') # remove the axis\n",
        " category = class_info[label.item()] # convert the label from ndarray to int then bring its class\n",
        " title= category.capitalize() + ', View No:' + str(viewNo)\n",
        " plt.title(title) # show the title above the img"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "b3bsGDtokjiB"
      },
      "source": [
        "# Training the Pre-trained Model (Stage 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JlDEHYBW0tf_"
      },
      "outputs": [],
      "source": [
        "# for training and testing\n",
        "##########################\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "categorical_y_test = to_categorical(y_test, 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "thhZjqz1fVmc"
      },
      "outputs": [],
      "source": [
        "# for training and testing\n",
        "##########################\n",
        "\n",
        "# Loading the Pre-Trained Model\n",
        "# Upload the required libraries\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "import time\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tqdm import tqdm\n",
        "\n",
        "# keras imports\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.applications.vgg19 import VGG19, preprocess_input\n",
        "from keras.applications.xception import Xception, preprocess_input\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
        "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.densenet import DenseNet201\n",
        "from keras.applications.nasnet import NASNetLarge\n",
        "from keras.applications.nasnet import NASNetMobile\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from keras.applications.resnet import ResNet50\n",
        "from keras.applications.resnet import ResNet101\n",
        "from keras.applications.resnet import ResNet152\n",
        "from keras.applications.resnet_v2 import ResNet50V2\n",
        "from keras.applications.resnet_v2 import ResNet101V2\n",
        "from keras.applications.resnet_v2 import ResNet152V2\n",
        "\n",
        "# filter warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.applications.vgg19 import VGG19, preprocess_input\n",
        "from keras.applications.xception import Xception, preprocess_input\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
        "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
        "from keras.applications.efficientnet import EfficientNetB1, preprocess_input\n",
        "from keras.applications.efficientnet import EfficientNetB2, preprocess_input\n",
        "from keras.applications.efficientnet import EfficientNetB3, preprocess_input\n",
        "from keras.applications.efficientnet import EfficientNetB4, preprocess_input\n",
        "from keras.applications.efficientnet import EfficientNetB5, preprocess_input\n",
        "from keras.applications.efficientnet import EfficientNetB6, preprocess_input\n",
        "from keras.applications.efficientnet import EfficientNetB7, preprocess_input\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.models import model_from_json\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense,GlobalAveragePooling2D\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from pycm import *\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import array\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from keras_tqdm import TQDMNotebookCallback\n",
        "from keras_tqdm import TQDMCallback\n",
        "#from keras_preprocessing.image import load_img\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import gradient_descent_v2\n",
        "from keras.optimizers import adam_v2\n",
        "from keras.layers import MaxPooling2D\n",
        "\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "from keras import optimizers\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.layers import ( # from tensorflow.keras.layers \n",
        "     Flatten, Dropout, Dense #,BatchNormalization, SeparableConv2D, Activation, \n",
        ")\n",
        "from tensorflow.keras.utils import plot_model ## from tensorflow.keras.utils \n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "M87drTWpht5Q"
      },
      "outputs": [],
      "source": [
        "# for training and testing\n",
        "##########################\n",
        "\n",
        "\n",
        "def plot_acc_loss(history, PLOT_NAME, model_name_txt): \n",
        "    fig = plt.figure(figsize=(10,5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    #plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    #plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper right')\n",
        "    plt.savefig(\"./Results/\"+str(dataset_version)+\"/\"+str(model_name_txt)+\"/\"+str(PLOT_NAME))\n",
        "    plt.show()\n",
        "\n",
        "def getPrediction(preds): # preds is the otput scors from softmax\n",
        "  im_class= np.argmax(preds, axis = 0) # the index as an array of one element , argmax Returns the indices of the maximum values along an axis\n",
        "  #\"the index of the class\"\n",
        "  idx= im_class\n",
        "  #\"the probability is\"\n",
        "  propability= preds[idx]\n",
        "  # the class label\n",
        "  label= class_info[idx]\n",
        "  return idx, label, propability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7rEa3J278ZX"
      },
      "outputs": [],
      "source": [
        "#all_deep_models = [VGG16, VGG19, MobileNet, InceptionV3, InceptionResNetV2, Xception, DenseNet121, DenseNet169, DenseNet201, NASNetMobile, MobileNetV2, ResNet50, ResNet101, ResNet152, ResNet50V2, ResNet101V2, ResNet152V2, NASNetLarge ]\n",
        "#all_model_name_txt = [\"VGG16\", \"VGG19\", \"MobileNet\", \"InceptionV3\", \"InceptionResNetV2\", \"Xception\", \"DenseNet121\", \"DenseNet169\", \"DenseNet201\", \"NASNetMobile\", \"MobileNetV2\",  \"ResNet50\", \"ResNet101\", \"ResNet152\", \"ResNet50V2\", \"ResNet101V2\", \"ResNet152V2\", \"NASNetLarge\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xNfeMGxr8CDh"
      },
      "outputs": [],
      "source": [
        "# for training and testing\n",
        "##########################\n",
        "# Note: spicify the deep model name\n",
        "##########################\n",
        "\n",
        "\n",
        "all_deep_models = [ResNet152]\n",
        "all_model_name_txt = [\"ResNet152\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "knMv73HO86-b"
      },
      "outputs": [],
      "source": [
        "# for training and testing\n",
        "##########################\n",
        "# Note: spicify the BATCH_SIZE based on the number of views\n",
        "#       spicify the img size that expected by the deep model\n",
        "##########################\n",
        "\n",
        "\n",
        "CLASSES = 40\n",
        "WIDTH = Img_Size\n",
        "HEIGHT = Img_Size\n",
        "BATCH_SIZE = 384 #20 shapes with a total of 400 views (20*20 =400) for 20-views version,  and 32 shapes with a total of 384 views (32*12 =384)) for 12-views version\n",
        "EPOCHS = 20 \n",
        "learning_rate = 0.0001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "import numpy as np   \n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, x_set, y_set, batch_size):\n",
        "        self.x, self.y = x_set, y_set\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        return batch_x, batch_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "import numpy as np   \n",
        "\n",
        "class DataGenerator1(Sequence):\n",
        "    def __init__(self, x_set, batch_size):\n",
        "        self.x = x_set\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        return batch_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "TzFMIE4oGHeJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "# for testing\n",
        "##########################\n",
        "\n",
        "i=0\n",
        "for deep_model in all_deep_models:\n",
        "    model_name = deep_model\n",
        "    model_name_txt = str(all_model_name_txt[i])\n",
        "    MODEL_FILE = \"./Results/\"+str(dataset_version)+\"/\"+str(model_name_txt)+\"/\"+str(model_name_txt)+\"_stage1.model\"\n",
        "    model_1 = load_model(MODEL_FILE)\n",
        "    i+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 7s 206ms/step\n",
            "Batch 1/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 2/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 3/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 4/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 5/494 processed.\n",
            "4/4 [==============================] - 1s 142ms/step\n",
            "Batch 6/494 processed.\n",
            "4/4 [==============================] - 1s 135ms/step\n",
            "Batch 7/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 8/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 9/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 10/494 processed.\n",
            "4/4 [==============================] - 1s 141ms/step\n",
            "Batch 11/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 12/494 processed.\n",
            "4/4 [==============================] - 1s 146ms/step\n",
            "Batch 13/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 14/494 processed.\n",
            "4/4 [==============================] - 1s 143ms/step\n",
            "Batch 15/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 16/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 17/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 18/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 19/494 processed.\n",
            "4/4 [==============================] - 1s 142ms/step\n",
            "Batch 20/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 21/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 22/494 processed.\n",
            "4/4 [==============================] - 1s 135ms/step\n",
            "Batch 23/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 24/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 25/494 processed.\n",
            "4/4 [==============================] - 1s 141ms/step\n",
            "Batch 26/494 processed.\n",
            "4/4 [==============================] - 1s 133ms/step\n",
            "Batch 27/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 28/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 29/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 30/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 31/494 processed.\n",
            "4/4 [==============================] - 1s 142ms/step\n",
            "Batch 32/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 33/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 34/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 35/494 processed.\n",
            "4/4 [==============================] - 1s 134ms/step\n",
            "Batch 36/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 37/494 processed.\n",
            "4/4 [==============================] - 1s 142ms/step\n",
            "Batch 38/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 39/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 40/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 41/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 42/494 processed.\n",
            "4/4 [==============================] - 1s 142ms/step\n",
            "Batch 43/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 44/494 processed.\n",
            "4/4 [==============================] - 1s 143ms/step\n",
            "Batch 45/494 processed.\n",
            "4/4 [==============================] - 1s 141ms/step\n",
            "Batch 46/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 47/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 48/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 49/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 50/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 51/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 52/494 processed.\n",
            "4/4 [==============================] - 1s 141ms/step\n",
            "Batch 53/494 processed.\n",
            "4/4 [==============================] - 1s 141ms/step\n",
            "Batch 54/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 55/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 56/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 57/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 58/494 processed.\n",
            "4/4 [==============================] - 1s 143ms/step\n",
            "Batch 59/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 60/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 61/494 processed.\n",
            "4/4 [==============================] - 1s 142ms/step\n",
            "Batch 62/494 processed.\n",
            "4/4 [==============================] - 1s 143ms/step\n",
            "Batch 63/494 processed.\n",
            "4/4 [==============================] - 1s 134ms/step\n",
            "Batch 64/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 65/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 66/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 67/494 processed.\n",
            "4/4 [==============================] - 1s 133ms/step\n",
            "Batch 68/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 69/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 70/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 71/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 72/494 processed.\n",
            "4/4 [==============================] - 1s 142ms/step\n",
            "Batch 73/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 74/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 75/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 76/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 77/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 78/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 79/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 80/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 81/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 82/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 83/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 84/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 85/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 86/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 87/494 processed.\n",
            "4/4 [==============================] - 1s 135ms/step\n",
            "Batch 88/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 89/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 90/494 processed.\n",
            "4/4 [==============================] - 1s 141ms/step\n",
            "Batch 91/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 92/494 processed.\n",
            "4/4 [==============================] - 1s 141ms/step\n",
            "Batch 93/494 processed.\n",
            "4/4 [==============================] - 1s 142ms/step\n",
            "Batch 94/494 processed.\n",
            "4/4 [==============================] - 1s 135ms/step\n",
            "Batch 95/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 96/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 97/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 98/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 99/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 100/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 101/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 102/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 103/494 processed.\n",
            "4/4 [==============================] - 1s 135ms/step\n",
            "Batch 104/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 105/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 106/494 processed.\n",
            "4/4 [==============================] - 1s 141ms/step\n",
            "Batch 107/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 108/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 109/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 110/494 processed.\n",
            "4/4 [==============================] - 1s 141ms/step\n",
            "Batch 111/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 112/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 113/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 114/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 115/494 processed.\n",
            "4/4 [==============================] - 1s 135ms/step\n",
            "Batch 116/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 117/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 118/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 119/494 processed.\n",
            "4/4 [==============================] - 1s 142ms/step\n",
            "Batch 120/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 121/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 122/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 123/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 124/494 processed.\n",
            "4/4 [==============================] - 1s 141ms/step\n",
            "Batch 125/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 126/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 127/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 128/494 processed.\n",
            "4/4 [==============================] - 1s 141ms/step\n",
            "Batch 129/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 130/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 131/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 132/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 133/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 134/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 135/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 136/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 137/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 138/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 139/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 140/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 141/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 142/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 143/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 144/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 145/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 146/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 147/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 148/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 149/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 150/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 151/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 152/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 153/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 154/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 155/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 156/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 157/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 158/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 159/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 160/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 161/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 162/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 163/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 164/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 165/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 166/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 167/494 processed.\n",
            "4/4 [==============================] - 1s 197ms/step\n",
            "Batch 168/494 processed.\n",
            "4/4 [==============================] - 2s 197ms/step\n",
            "Batch 169/494 processed.\n",
            "4/4 [==============================] - 3s 426ms/step\n",
            "Batch 170/494 processed.\n",
            "4/4 [==============================] - 2s 220ms/step\n",
            "Batch 171/494 processed.\n",
            "4/4 [==============================] - 1s 150ms/step\n",
            "Batch 172/494 processed.\n",
            "4/4 [==============================] - 3s 452ms/step\n",
            "Batch 173/494 processed.\n",
            "4/4 [==============================] - 2s 325ms/step\n",
            "Batch 174/494 processed.\n",
            "4/4 [==============================] - 2s 241ms/step\n",
            "Batch 175/494 processed.\n",
            "4/4 [==============================] - 2s 321ms/step\n",
            "Batch 176/494 processed.\n",
            "4/4 [==============================] - 1s 176ms/step\n",
            "Batch 177/494 processed.\n",
            "4/4 [==============================] - 1s 166ms/step\n",
            "Batch 178/494 processed.\n",
            "4/4 [==============================] - 1s 144ms/step\n",
            "Batch 179/494 processed.\n",
            "4/4 [==============================] - 2s 147ms/step\n",
            "Batch 180/494 processed.\n",
            "4/4 [==============================] - 2s 473ms/step\n",
            "Batch 181/494 processed.\n",
            "4/4 [==============================] - 1s 141ms/step\n",
            "Batch 182/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 183/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 184/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 185/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 186/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 187/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 188/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 189/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 190/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 191/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 192/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 193/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 194/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 195/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 196/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 197/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 198/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 199/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 200/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 201/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 202/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 203/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 204/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 205/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 206/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 207/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 208/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 209/494 processed.\n",
            "4/4 [==============================] - 1s 134ms/step\n",
            "Batch 210/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 211/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 212/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 213/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 214/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 215/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 216/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 217/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 218/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 219/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 220/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 221/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 222/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 223/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 224/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 225/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 226/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 227/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 228/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 229/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 230/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 231/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 232/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 233/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 234/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 235/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 236/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 237/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 238/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 239/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 240/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 241/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 242/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 243/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 244/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 245/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 246/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 247/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 248/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 249/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 250/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 251/494 processed.\n",
            "4/4 [==============================] - 1s 134ms/step\n",
            "Batch 252/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 253/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 254/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 255/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 256/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 257/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 258/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 259/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 260/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 261/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 262/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 263/494 processed.\n",
            "4/4 [==============================] - 1s 134ms/step\n",
            "Batch 264/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 265/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 266/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 267/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 268/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 269/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 270/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 271/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 272/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 273/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 274/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 275/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 276/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 277/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 278/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 279/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 280/494 processed.\n",
            "4/4 [==============================] - 1s 135ms/step\n",
            "Batch 281/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 282/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 283/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 284/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 285/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 286/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 287/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 288/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 289/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 290/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 291/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 292/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 293/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 294/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 295/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 296/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 297/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 298/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 299/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 300/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 301/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 302/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 303/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 304/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 305/494 processed.\n",
            "4/4 [==============================] - 1s 134ms/step\n",
            "Batch 306/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 307/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 308/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 309/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 310/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 311/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 312/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 313/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 314/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 315/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 316/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 317/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 318/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 319/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 320/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 321/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 322/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 323/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 324/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 325/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 326/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 327/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 328/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 329/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 330/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 331/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 332/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 333/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 334/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 335/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 336/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 337/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 338/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 339/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 340/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 341/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 342/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 343/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 344/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 345/494 processed.\n",
            "4/4 [==============================] - 1s 135ms/step\n",
            "Batch 346/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 347/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 348/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 349/494 processed.\n",
            "4/4 [==============================] - 1s 134ms/step\n",
            "Batch 350/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 351/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 352/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 353/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 354/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 355/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 356/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 357/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 358/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 359/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 360/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 361/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 362/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 363/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 364/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 365/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 366/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 367/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 368/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 369/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 370/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 371/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 372/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 373/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 374/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 375/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 376/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 377/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 378/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 379/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 380/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 381/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 382/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 383/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 384/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 385/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 386/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 387/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 388/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 389/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 390/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 391/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 392/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 393/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 394/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 395/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 396/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 397/494 processed.\n",
            "4/4 [==============================] - 1s 134ms/step\n",
            "Batch 398/494 processed.\n",
            "4/4 [==============================] - 1s 141ms/step\n",
            "Batch 399/494 processed.\n",
            "4/4 [==============================] - 1s 135ms/step\n",
            "Batch 400/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 401/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 402/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 403/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 404/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 405/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 406/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 407/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 408/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 409/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 410/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 411/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 412/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 413/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 414/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 415/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 416/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 417/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 418/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 419/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 420/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 421/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 422/494 processed.\n",
            "4/4 [==============================] - 1s 135ms/step\n",
            "Batch 423/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 424/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 425/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 426/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 427/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 428/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 429/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 430/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 431/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 432/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 433/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 434/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 435/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 436/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 437/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 438/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 439/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 440/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 441/494 processed.\n",
            "4/4 [==============================] - 1s 135ms/step\n",
            "Batch 442/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 443/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 444/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 445/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 446/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 447/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 448/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 449/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 450/494 processed.\n",
            "4/4 [==============================] - 1s 135ms/step\n",
            "Batch 451/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 452/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 453/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 454/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 455/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 456/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 457/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 458/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 459/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 460/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 461/494 processed.\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Batch 462/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 463/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 464/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 465/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 466/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 467/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 468/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 469/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 470/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 471/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 472/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 473/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 474/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 475/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 476/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 477/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 478/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 479/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 480/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 481/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 482/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 483/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 484/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 485/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 486/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 487/494 processed.\n",
            "4/4 [==============================] - 1s 136ms/step\n",
            "Batch 488/494 processed.\n",
            "4/4 [==============================] - 1s 135ms/step\n",
            "Batch 489/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 490/494 processed.\n",
            "4/4 [==============================] - 1s 137ms/step\n",
            "Batch 491/494 processed.\n",
            "4/4 [==============================] - 1s 138ms/step\n",
            "Batch 492/494 processed.\n",
            "4/4 [==============================] - 1s 139ms/step\n",
            "Batch 493/494 processed.\n",
            "2/2 [==============================] - 1s 641ms/step\n",
            "Batch 494/494 processed.\n",
            "Feature extraction completed.\n"
          ]
        }
      ],
      "source": [
        "# extract and save the features incrementally as baches and clear the memory occupied by the previous batches.\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "# Constants\n",
        "batch_size = 100\n",
        "output_directory = \"./data/\"\n",
        "\n",
        "# Calculate the number of batches\n",
        "num_images = test_NoOfSamples\n",
        "num_batches = int(np.ceil(num_images / batch_size))\n",
        "\n",
        "# Initialize an empty list to store features\n",
        "all_features = []\n",
        "\n",
        "# Iterate through each batch\n",
        "#for i in range(1500, 1969):\n",
        "for i in range(num_batches):\n",
        "    start_index = i * batch_size\n",
        "    end_index = min((i + 1) * batch_size, num_images)\n",
        "\n",
        "    # Initialize an empty list to store features in the current batch\n",
        "    batch_features = []\n",
        "\n",
        "    # Save images in the current batch as features\n",
        "    for j in range(start_index, end_index):\n",
        "        batch_features.append(X_test[j])\n",
        "\n",
        "    # Convert batch features list to a NumPy array\n",
        "    batch_features = np.array(batch_features)\n",
        "\n",
        "    # Extract features of the the current batch using the model\n",
        "    batch_features = model_1.predict(batch_features, verbose=1) \n",
        "\n",
        "    # Append batch features to the list of all features\n",
        "    all_features.append(batch_features)\n",
        "\n",
        "    # Clear session to free up GPU memory\n",
        "    K.clear_session() # a K.clear_session() call after each batch to clear the TensorFlow session and free up GPU memory. \n",
        "\n",
        "    print(f\"Batch {i+1}/{num_batches} processed.\")\n",
        "\n",
        "    # Save features after every 10 batches (adjust as needed)\n",
        "    if (i+1) % 10 == 0 or (i+1) == num_batches:\n",
        "        # Concatenate all batches of features into a single NumPy array\n",
        "        all_features = np.concatenate(all_features)\n",
        "\n",
        "        # Save features to a separate file\n",
        "        output_file = f\"./data/features_batch_{i+1}.npy\"\n",
        "        np.save(output_file, all_features) # This allows you to save the features incrementally and clear the memory occupied by the previous batches.\n",
        "        # Clear the list of features to save memory\n",
        "        all_features = []\n",
        "\n",
        "print(\"Feature extraction completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "features_batch_ 10  is appended\n",
            "features_batch_ 20  is appended\n",
            "features_batch_ 30  is appended\n",
            "features_batch_ 40  is appended\n",
            "features_batch_ 50  is appended\n",
            "features_batch_ 60  is appended\n",
            "features_batch_ 70  is appended\n",
            "features_batch_ 80  is appended\n",
            "features_batch_ 90  is appended\n",
            "features_batch_ 100  is appended\n",
            "features_batch_ 110  is appended\n",
            "features_batch_ 120  is appended\n",
            "features_batch_ 130  is appended\n",
            "features_batch_ 140  is appended\n",
            "features_batch_ 150  is appended\n",
            "features_batch_ 160  is appended\n",
            "features_batch_ 170  is appended\n",
            "features_batch_ 180  is appended\n",
            "features_batch_ 190  is appended\n",
            "features_batch_ 200  is appended\n",
            "features_batch_ 210  is appended\n",
            "features_batch_ 220  is appended\n",
            "features_batch_ 230  is appended\n",
            "features_batch_ 240  is appended\n",
            "features_batch_ 250  is appended\n",
            "features_batch_ 260  is appended\n",
            "features_batch_ 270  is appended\n",
            "features_batch_ 280  is appended\n",
            "features_batch_ 290  is appended\n",
            "features_batch_ 300  is appended\n",
            "features_batch_ 310  is appended\n",
            "features_batch_ 320  is appended\n",
            "features_batch_ 330  is appended\n",
            "features_batch_ 340  is appended\n",
            "features_batch_ 350  is appended\n",
            "features_batch_ 360  is appended\n",
            "features_batch_ 370  is appended\n",
            "features_batch_ 380  is appended\n",
            "features_batch_ 390  is appended\n",
            "features_batch_ 400  is appended\n",
            "features_batch_ 410  is appended\n",
            "features_batch_ 420  is appended\n",
            "features_batch_ 430  is appended\n",
            "features_batch_ 440  is appended\n",
            "features_batch_ 450  is appended\n",
            "features_batch_ 460  is appended\n",
            "features_batch_ 470  is appended\n",
            "features_batch_ 480  is appended\n",
            "features_batch_ 490  is appended\n",
            "features_batch_494 is appended\n",
            "All testing features are grouped into a single NumPy array.\n",
            "Shape: (49360, 7, 7, 2048)\n",
            "Data type: float32\n"
          ]
        }
      ],
      "source": [
        "# Grouping training features into a single NumPy array.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Calculate the number of batches\n",
        "batch_size=100\n",
        "num_images = test_NoOfSamples\n",
        "num_batches = int(np.ceil(num_images / batch_size))\n",
        "#num_batches = 1969  # Total number of batches\n",
        "batch_interval = 10  # Interval between batches\n",
        "\n",
        "# Initialize an empty list to store features\n",
        "all_testing_features = []\n",
        "\n",
        "# Iterate through each batch\n",
        "for i in range(1, num_batches + 1):\n",
        "    # Check if the current batch is within the desired interval\n",
        "    if i % batch_interval == 0:\n",
        "        # Load features from the file\n",
        "        features_file = f\"./data/features_batch_{i}.npy\"\n",
        "        batch_features = np.load(features_file).astype(np.float16)\n",
        "\n",
        "        # Append batch features to the list of all features\n",
        "        all_testing_features.append(batch_features)\n",
        "        print(\"features_batch_\",str(i),\" is appended\")\n",
        "\n",
        "        if i == 490: # the batch before the last batch\n",
        "            features_file = f\"./data/features_batch_494.npy\"\n",
        "            batch_features = np.load(features_file)\n",
        "            # Append batch features to the list of all features\n",
        "            all_testing_features.append(batch_features)\n",
        "            print(\"features_batch_494 is appended\")\n",
        "\n",
        "    \n",
        "\n",
        "# Concatenate all batches of features into a single NumPy array\n",
        "all_testing_features = np.concatenate(all_testing_features)\n",
        "\n",
        "# Save all features to a single NumPy array file\n",
        "output_file = \"./data/all_testing_features.npy\"\n",
        "np.save(output_file, all_testing_features)\n",
        "\n",
        "print(\"All testing features are grouped into a single NumPy array.\")\n",
        "\n",
        "# The objects must then be expanded from a 3D array to a 4D array with the dimensions [samples, rows, cols, channels]\n",
        "print(\"Shape:\", all_testing_features.shape) # VGG16 Shape: (49360, 7, 7, 2048)\n",
        "print(\"Data type:\", all_testing_features.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load all features to a single NumPy array file\n",
        "\n",
        "features_file = \"./data/all_testing_features.npy\"\n",
        "all_testing_features = np.load(features_file)\n",
        "\n",
        "print(\"All testing features are load into a single NumPy array.\")\n",
        "\n",
        "# Verify the shape and data type of the loaded array\n",
        "print(\"Shape:\", all_testing_features.shape) # ResNet50 Shape: (49360, 7, 7, 2048)\n",
        "print(\"Data type:\", all_testing_features.dtype)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "N3KA4HGC0QiG"
      },
      "source": [
        "# Convert views to feature vectors\n",
        "\n",
        "https://towardsdatascience.com/image-similarity-detection-in-action-with-tensorflow-2-0-b8d9a78b2509\n",
        "\n",
        "An image feature vector is a list of numbers that represents a whole image, typically used for image similarity calculations or image classification tasks.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "n8QyDkbJ-Upw"
      },
      "source": [
        "## Feature vectors using flatten\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(49360, 100352)\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "# convert to flatten feature vector\n",
        "########################\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Flatten each element in the array\n",
        "flattened_arr = all_testing_features.reshape(all_testing_features.shape[0], -1)\n",
        "\n",
        "# Update the original array with the flattened elements\n",
        "all_testing_features = flattened_arr\n",
        "\n",
        "del flattened_arr\n",
        "\n",
        "# Print the shape of the updated array\n",
        "print(all_testing_features.shape) #(49360, 100352)\n",
        "print(type(all_testing_features))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "G7V3JEJo_NwK"
      },
      "source": [
        "# View Selection: Importance Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "JUqeSC1nKT7X"
      },
      "outputs": [],
      "source": [
        "# for training and testing\n",
        "##########################\n",
        "\n",
        "\n",
        "# Define Similarity Metrics\n",
        "\n",
        "import math\n",
        "from math import sqrt\n",
        "\n",
        "# Define Cosine Similarity\n",
        "def cosineSim(a1,a2): # after avoid division by zero\n",
        "    summ = 0\n",
        "    suma1 = 0\n",
        "    sumb1 = 0\n",
        "    for i,j in zip(a1, a2):\n",
        "        suma1 += i * i\n",
        "        sumb1 += j*j\n",
        "        summ += i*j\n",
        "        eps= 0.00000001 #Small value to avoid division by zero. Default: 1e-8\n",
        "    denominator = (sqrt(suma1))*(sqrt(sumb1))\n",
        "    MaxDenominator = max(denominator, eps)\n",
        "    cosine_sim = summ / MaxDenominator\n",
        "    #cosine_sim = 1 - cosine_sim # to clalculate the cosine distance\n",
        "    #CS_SCORE= 1-CS_SCORE # DISTANCE SIMILARITY\n",
        "    # CS_SCORE= 1-CS_SCORE # to measure the cosine distance\n",
        "    return cosine_sim\n",
        "\n",
        "# Define jaccard Similarity\n",
        "def jaccard_similarity(list1, list2):\n",
        "    intersection = len(list(set(list1).intersection(list2)))\n",
        "    union = (len(list1) + len(list2)) - intersection\n",
        "    return float(intersection) / union\n",
        "\n",
        "def average(x):\n",
        "    assert len(x) > 0\n",
        "    return float(sum(x)) / len(x)\n",
        "\n",
        "# Define pearson Similarity\n",
        "def pearson_def(x, y):\n",
        "    assert len(x) == len(y)\n",
        "    n = len(x)\n",
        "    assert n > 0\n",
        "    avg_x = average(x)\n",
        "    avg_y = average(y)\n",
        "    diffprod = 0\n",
        "    xdiff2 = 0\n",
        "    ydiff2 = 0\n",
        "    for idx in range(n):\n",
        "        xdiff = x[idx] - avg_x\n",
        "        ydiff = y[idx] - avg_y\n",
        "        diffprod += xdiff * ydiff\n",
        "        xdiff2 += xdiff * xdiff\n",
        "        ydiff2 += ydiff * ydiff\n",
        "\n",
        "    return diffprod / math.sqrt(xdiff2 * ydiff2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "IFBsBQl-Og6A"
      },
      "outputs": [],
      "source": [
        "# for training and testing\n",
        "##########################\n",
        "# Note: spicify the fig size based on the number of views\n",
        "##########################\n",
        "\n",
        "\n",
        "def Plot_with_Important_Scores(im_ls, GuidedGradCAM, IS, classes, ViewNo, n):\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    #random.shuffle(im_ls)\n",
        "    #plt.subplots(figsize=(30, 10*n))\n",
        "    #k=1\n",
        "    for i in range(n):\n",
        "        plt.figure(figsize=(15, 15))\n",
        "        k=1\n",
        "        #img = cv2.imread(path[i])\n",
        "        img= im_ls[i]\n",
        "        Guided_img= GuidedGradCAM[i]\n",
        "        Important_Score= IS[i]\n",
        "\n",
        "        # Show original image\n",
        "        plt.subplot(3,4,k) # for 12 view\n",
        "        plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
        "        label = classes[i] #take the label of the sample image\n",
        "        viewNo= ViewNo[i]\n",
        "        category = class_info[label.item()] # convert the label from ndarray to int then bring its class\n",
        "        #print(category)\n",
        "        title= category.capitalize() + ', View No:' + str(viewNo)\n",
        "        plt.title(title, fontsize=10)\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        # Show guided GradCAM\n",
        "        plt.subplot(3,4,k+1)\n",
        "        plt.imshow(cv2.cvtColor(Guided_img,cv2.COLOR_BGR2RGB))\n",
        "        #title= \"Guided GradCAM\" + ', I\\u0302\\u2082'+ str(viewNo)+':'+ str(Important_Score)\n",
        "        title= 'Important Score:'+ str(Important_Score)\n",
        "        plt.title(title, fontsize=10)\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "        #k += 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F8_JRvJqV5lR",
        "outputId": "6a288eb5-a527-4817-9e08-26ad32c1f1cb"
      },
      "outputs": [],
      "source": [
        "# for testing\n",
        "##########################\n",
        "\n",
        "# Applay View Selection\n",
        "#######################\n",
        "#######################\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "start_index= 0\n",
        "test_object_label=0\n",
        "end_index= num_views \n",
        "\n",
        "n= len(all_testing_features)\n",
        "object_views=np.zeros(num_views)\n",
        "\n",
        "test_NoOfObject= test_NoOfSamples//num_views\n",
        "NoOfPixels= WIDTH *HEIGHT*3\n",
        "\n",
        "X_test_global_descriptor=[]\n",
        "y_test_global_descriptor=[]\n",
        "IS_test_global_descriptor=[]\n",
        "viewNo_test_global_descriptor=[]\n",
        "\n",
        "\n",
        "finished = \"false\"\n",
        "while finished != \"true\":\n",
        "# make smaller array conataining only the FVs of the 12 views of one object\n",
        "# by slicing the test_array to take the n views each times\n",
        "  object_views= all_testing_features[start_index:end_index]\n",
        "  test_object_label= y_test[start_index]\n",
        "\n",
        "# Calculate importance scores\n",
        "#############################\n",
        "  k=0 # counter for the view\n",
        "  j= 0 # counter for the other comparied to view\n",
        "  test_importance_Scores=np.zeros(num_views)\n",
        "# compute the importance scores of the 12 views of one object\n",
        "  for k in range(num_views): # k is the view that I want to calculate its score\n",
        "    View_Score=0\n",
        "    for j in range(num_views):\n",
        "      CS_SCORE= cosineSim(object_views[k],object_views[j]) # CS_SCORE is the Cosine Similarity\n",
        "      View_Score= View_Score + CS_SCORE\n",
        "    test_importance_Scores[k]=View_Score\n",
        "\n",
        "# Normalize the importance scores\n",
        "#################################\n",
        "  test_normalized_importance_Scores= [float(i)/sum(test_importance_Scores) for i in test_importance_Scores] #to normalize against the sum to ensure that the sum is always 1.0 (or as close to as possible).\n",
        "\n",
        "  #if start_index == 0:\n",
        "    #Plot_with_Important_Scores(X_test, X_test_GudiedGradCAM, test_normalized_importance_Scores, y_test, ViewNo_test, n=num_views)\n",
        "\n",
        "\n",
        "# Compute the global descriptor of an object (the most similar view which has the maximum important score\\Cosine Similarity )\n",
        "###############################################################################\n",
        "  \n",
        "  arr = np.array(test_normalized_importance_Scores) #convert test_normalized_importance_Scores from list to array\n",
        "  \n",
        "  if selection_mechanism == 'MSV':\n",
        "    view_pos = np.argmax(arr) # find the index of the view that contain the  maximum important score\\Cosine Similarity (that most similar to other views)\n",
        "  elif selection_mechanism == 'MDV':\n",
        "    view_pos = np.argmin(arr) # find the index of the view that contain the  minimum important score\\Cosine Similarity (that most dissimilar to other views)\n",
        "\n",
        "  IS_test_global_descriptor.append(test_normalized_importance_Scores[view_pos]) # save the maximum or minimum important score\\Cosine Similarity\n",
        "  X_test_global_descriptor.append(object_views[view_pos]) # take the view that contain the maximum or minimum important score\\Cosine Similarity (that most similar to other views) as a global_descriptor to the object\n",
        "  y_test_global_descriptor.append(test_object_label) # take the label of the view that has the maximum or minimum important score\\Cosine Similarity\n",
        "  viewNo_test_global_descriptor.append(view_pos+1)\n",
        "\n",
        "# Increase indexes to go to the next object\n",
        "  start_index+= num_views\n",
        "  end_index+= num_views\n",
        "\n",
        "  if (end_index > n): # go through all images and break if it exceed the array index\n",
        "    finished = \"true\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for testing\n",
        "##########################\n",
        "\n",
        "# convert the new labels to categorical labels\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "categorical_y_test_global_descriptor = to_categorical(y_test_global_descriptor, 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "7qL8icJl6eBk"
      },
      "outputs": [],
      "source": [
        "# for training and testing\n",
        "##########################\n",
        "\n",
        "# to print the full NumPy array, without truncation\n",
        "\n",
        "import sys\n",
        "import numpy\n",
        "numpy.set_printoptions(threshold=sys.maxsize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "# for testing\n",
        "##########################\n",
        "\n",
        "# convert the training data from (list) to (nparray)\n",
        "y_test_global_descriptor = np.array(y_test_global_descriptor)\n",
        "X_test_global_descriptor= np.array(X_test_global_descriptor)\n",
        "\n",
        "# ensure that both are ndarray\n",
        "print(type(X_test_global_descriptor))\n",
        "print(type(y_test_global_descriptor))\n",
        "print(type(categorical_y_test_global_descriptor))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oPfR-vMiXqx-"
      },
      "source": [
        "## Do the testing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2468, 100352)\n"
          ]
        }
      ],
      "source": [
        "# for testing\n",
        "##########################\n",
        "# extract the nunmber of tested objects (samples) and thier number of features (features)\n",
        "\n",
        "print(X_test_global_descriptor.shape)\n",
        "samples= X_test_global_descriptor.shape[0] #2468\n",
        "features= X_test_global_descriptor.shape[1] # rows* cols* channels = 7*7*2048 =100352"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2468, 100352)\n"
          ]
        }
      ],
      "source": [
        "# for testing\n",
        "##########################\n",
        "\n",
        "# Reshape the feature vectors into a 2D matrix\n",
        "\n",
        "# we have a list of samples precomputed feature vectors (of samples objects),\n",
        "# each with a length of features\n",
        "X_test_global_descriptor = np.array(X_test_global_descriptor).reshape(samples, features)\n",
        "print(X_test_global_descriptor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save all features and labels to a single NumPy array file\n",
        "output_file = \"./data/all_testing_labels_global_descriptor.npy\"\n",
        "np.save(output_file, y_test_global_descriptor)\n",
        "\n",
        "output_file = \"./data/all_testing_global_descriptor.npy\"\n",
        "np.save(output_file, X_test_global_descriptor)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fFz92aCAT9fn"
      },
      "source": [
        "# Prediction and Results calculation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "3SkfDE2TY84l"
      },
      "outputs": [],
      "source": [
        "# for testing\n",
        "##########################\n",
        "# Note: spicify the classes if using the modelnet10\n",
        "##########################\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from operator import truediv\n",
        "import matplotlib.pylab as plt\n",
        "#import numpy as np\n",
        "\n",
        "\n",
        "def plot_confusion_matrix_manual(cm, cmap=plt.cm.Blues):\n",
        "    classes = ['airplane', 'bathtub', 'bed', 'bench', 'bookshelf', 'bottle', 'bowl', 'car', 'chair',\n",
        "                   'cone', 'cup', 'curtain', 'desk', 'door', 'dresser', 'flower_pot', 'glass_box',\n",
        "                   'guitar', 'keyboard', 'lamp', 'laptop', 'mantel', 'monitor', 'night_stand',\n",
        "                   'person', 'piano', 'plant', 'radio', 'range_hood', 'sink', 'sofa', 'stairs',\n",
        "                   'stool', 'table', 'tent', 'toilet', 'tv_stand', 'vase', 'wardrobe', 'xbox']\n",
        "    plt.rcParams['savefig.dpi'] = 300\n",
        "    plt.rcParams['figure.dpi'] = 300\n",
        "    \n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    plt.tick_params(labelsize=5)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(\n",
        "        xticks=np.arange(cm.shape[1]),\n",
        "        yticks=np.arange(cm.shape[0]),\n",
        "        # ... and label them with the respective list entries\n",
        "        xticklabels=classes,\n",
        "        yticklabels=classes)\n",
        "    plt.title('Confusion matrix', fontsize=6)\n",
        "    plt.xlabel('Predicted label', fontsize=6)\n",
        "    plt.ylabel('True label', fontsize=6)\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(),\n",
        "             rotation=45,\n",
        "             ha=\"right\",\n",
        "             rotation_mode=\"anchor\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for training and testing\n",
        "##########################\n",
        "# to print the full NumPy array, without truncation\n",
        "\n",
        "import sys\n",
        "import numpy\n",
        "numpy.set_printoptions(threshold=sys.maxsize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test FCL: 20epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 40)                4014120   \n",
            "=================================================================\n",
            "Total params: 4,014,120\n",
            "Trainable params: 4,014,120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# for testing\n",
        "########################## Load FCL: 20epochs ##############################\n",
        "\n",
        "i=0\n",
        "for deep_model in all_deep_models:\n",
        "    model_name = deep_model\n",
        "    model_name_txt = str(all_model_name_txt[i])\n",
        "    # Load the fully-connected Layer (FCL)\n",
        "    MODEL_FILE = \"./Results/\"+str(dataset_version)+\"/\"+str(model_name_txt)+\"/\"+\"20epochs\"+\"/\"+str(model_name_txt)+\"_stage2_FCL.model\"\n",
        "    model_2 = load_model(MODEL_FILE)\n",
        "    model_2.summary()\n",
        "    i+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for testing\n",
        "########################## Test FCL: 20epochs ##############################\n",
        "\n",
        "#import seaborn as sn\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "# Do the prediction\n",
        "predictions = model_2.predict(X_test_global_descriptor) # predict the classe of the test images\n",
        "(samples, classes)= predictions.shape\n",
        "\n",
        "# Extract the index of prediction from the preds_scores_matrix\n",
        "y_pred= np.zeros_like(y_test_global_descriptor)\n",
        "y_pred_classes= np.empty(len(y_test_global_descriptor), dtype=object)\n",
        "\n",
        "for i in range(samples):\n",
        "   preds_scores_matrix = predictions[i, :]\n",
        "   idx, label, propability = getPrediction(preds_scores_matrix)\n",
        "   y_pred[i]= idx\n",
        "   y_pred_classes[i] = label\n",
        "\n",
        "\n",
        "\n",
        "# return the predicted classe of the test images as labels such as \"airplane\n",
        "y_true_classes = np.empty(len(y_test_global_descriptor), dtype=object)\n",
        "\n",
        "for t in range (len(y_test_global_descriptor)):\n",
        "   y_true_classes[t] = class_info[y_test_global_descriptor[t]]\n",
        "\n",
        "\n",
        "\n",
        "#Confution Matrix and Classification Report\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(y_true_classes, y_pred_classes))\n",
        "\n",
        "\n",
        "\n",
        "print('Classification Report')\n",
        "\n",
        "target_names = ['airplane', 'bathtub', 'bed', 'bench', 'bookshelf', 'bottle', 'bowl', 'car', 'chair', 'cone',\n",
        "                'cup', 'curtain', 'desk', 'door', 'dresser', 'flower_pot', 'glass_box', 'guitar', 'keyboard', 'lamp',\n",
        "                'laptop', 'mantel', 'monitor', 'night_stand', 'person', 'piano', 'plant', 'radio', 'range_hood', 'sink',\n",
        "                'sofa', 'stairs','stool', 'table', 'tent', 'toilet', 'tv_stand', 'vase', 'wardrobe', 'xbox']\n",
        "\n",
        "print(classification_report(y_true_classes, y_pred_classes, target_names=target_names))\n",
        "print (\"--- y_true_classes\")\n",
        "print (y_true_classes)\n",
        "print (\"--- y_pred_classes\")\n",
        "print (y_pred_classes)\n",
        "ccm = confusion_matrix(y_true_classes, y_pred_classes) # Create ConfusionMatrix From Data\n",
        "\n",
        "results = \"./Results/\"+str(dataset_version)+\"/\"+str(model_name_txt)+\"/\"+str(model_name_txt)+\"_20epochs_FCL_Results.txt\"\n",
        "f = open(results, \"w\")\n",
        "cm = ConfusionMatrix(actual_vector=y_true_classes, predict_vector=y_pred_classes) # Create ConfusionMatrix From categorical Data\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=ccm, display_labels=target_names)\n",
        "disp.plot(cmap=plt.cm.Blues, xticks_rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"./Results/\"+str(dataset_version)+\"/\"+str(model_name_txt)+\"/\"+\"20epochs_FCL_ConfusionMatrix.png\", pad_inches=5)\n",
        "plt.tick_params(axis='both', which='major', labelsize=5)\n",
        "plt.show()\n",
        "\n",
        "f.write(\"{}\\n\".format(cm))\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.99      1.00      1.00       100\n",
            "     bathtub       0.88      0.58      0.70        50\n",
            "         bed       0.87      0.90      0.89       100\n",
            "       bench       0.57      0.80      0.67        20\n",
            "   bookshelf       0.79      0.85      0.82       100\n",
            "      bottle       0.91      0.93      0.92       100\n",
            "        bowl       0.74      0.85      0.79        20\n",
            "         car       0.98      0.99      0.99       100\n",
            "       chair       0.82      0.92      0.87       100\n",
            "        cone       0.90      0.95      0.93        20\n",
            "         cup       0.58      0.55      0.56        20\n",
            "     curtain       0.86      0.95      0.90        20\n",
            "        desk       0.73      0.72      0.73        86\n",
            "        door       0.83      0.95      0.88        20\n",
            "     dresser       0.83      0.84      0.83        86\n",
            "  flower_pot       0.36      0.60      0.45        20\n",
            "   glass_box       0.76      0.74      0.75       100\n",
            "      guitar       0.98      0.98      0.98       100\n",
            "    keyboard       0.95      1.00      0.98        20\n",
            "        lamp       0.74      0.70      0.72        20\n",
            "      laptop       0.59      0.80      0.68        20\n",
            "      mantel       0.84      0.86      0.85       100\n",
            "     monitor       0.85      0.91      0.88       100\n",
            " night_stand       0.69      0.69      0.69        86\n",
            "      person       1.00      0.95      0.97        20\n",
            "       piano       0.81      0.68      0.74       100\n",
            "       plant       0.94      0.83      0.88       100\n",
            "       radio       0.56      0.50      0.53        20\n",
            "  range_hood       0.91      0.75      0.82       100\n",
            "        sink       0.46      0.60      0.52        20\n",
            "        sofa       0.84      0.93      0.88       100\n",
            "      stairs       0.75      0.60      0.67        20\n",
            "       stool       0.62      0.65      0.63        20\n",
            "       table       0.80      0.71      0.75       100\n",
            "        tent       0.38      0.60      0.46        20\n",
            "      toilet       0.89      0.93      0.91       100\n",
            "    tv_stand       0.71      0.59      0.64       100\n",
            "        vase       0.81      0.79      0.80       100\n",
            "    wardrobe       0.47      0.45      0.46        20\n",
            "        xbox       0.65      0.55      0.59        20\n",
            "\n",
            "    accuracy                           0.82      2468\n",
            "   macro avg       0.77      0.78      0.77      2468\n",
            "weighted avg       0.82      0.82      0.82      2468\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_true_classes, y_pred_classes, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Accuracy:\n",
            "airplane = 0.99\n",
            "bathtub = 0.75\n",
            "bed = 0.93\n",
            "bench = 0.55\n",
            "bookshelf = 0.91\n",
            "bottle = 0.6\n",
            "bowl = 0.6\n",
            "car = 0.58\n",
            "chair = 0.98\n",
            "cone = 0.74\n",
            "cup = 0.55\n",
            "curtain = 0.93\n",
            "desk = 0.45\n",
            "door = 0.6\n",
            "dresser = 0.68\n",
            "flower_pot = 0.7209302325581395\n",
            "glass_box = 0.95\n",
            "guitar = 0.7\n",
            "keyboard = 0.85\n",
            "lamp = 0.5\n",
            "laptop = 0.92\n",
            "mantel = 0.79\n",
            "monitor = 0.8\n",
            "night_stand = 0.86\n",
            "person = 0.95\n",
            "piano = 0.93\n",
            "plant = 0.71\n",
            "radio = 0.83\n",
            "range_hood = 0.9\n",
            "sink = 1.0\n",
            "sofa = 1.0\n",
            "stairs = 0.65\n",
            "stool = 0.85\n",
            "table = 0.686046511627907\n",
            "tent = 0.59\n",
            "toilet = 0.95\n",
            "tv_stand = 0.8\n",
            "vase = 0.8372093023255814\n",
            "wardrobe = 0.95\n",
            "xbox = 0.6\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "Overall Accuracy: 81.52350081037277 %\n",
            "Average Accuracy: 77.91046511627906 %\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Obtain the true labels and predicted labels\n",
        "true_labels = y_true_classes  # Replace with your true labels\n",
        "predicted_labels = y_pred_classes # Replace with your predicted labels\n",
        "\n",
        "# Calculate overall accuracy\n",
        "overall_accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "\n",
        "# Calculate average accuracy\n",
        "class_labels = set(true_labels)  # Get the unique class labels\n",
        "num_classes = len(class_labels)\n",
        "class_accuracies = []\n",
        "\n",
        "for label in class_labels:\n",
        "    # Filter the true and predicted labels corresponding to the current class\n",
        "    true_labels_class = [true_labels[i] for i in range(len(true_labels)) if true_labels[i] == label]\n",
        "    predicted_labels_class = [predicted_labels[i] for i in range(len(predicted_labels)) if true_labels[i] == label]\n",
        "    \n",
        "    # Calculate accuracy for the current class\n",
        "    class_accuracy = accuracy_score(true_labels_class, predicted_labels_class)\n",
        "    class_accuracies.append(class_accuracy)\n",
        "\n",
        "average_accuracy = sum(class_accuracies) / num_classes\n",
        "\n",
        "# Print overall accuracy and average accuracy\n",
        "print(\"Class Accuracy:\")\n",
        "for i in range(40):\n",
        "    print(target_names[i], \"=\", class_accuracies[i])\n",
        "print(\"------------------------------------------\")\n",
        "print(\"------------------------------------------\")\n",
        "print(\"------------------------------------------\")\n",
        "print(\"Overall Accuracy:\", overall_accuracy*100, \"%\")\n",
        "print(\"Average Accuracy:\", average_accuracy*100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test FCL: 30epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 40)                4014120   \n",
            "=================================================================\n",
            "Total params: 4,014,120\n",
            "Trainable params: 4,014,120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# for testing\n",
        "########################## Load FCL: 30epochs ##############################\n",
        "\n",
        "i=0\n",
        "for deep_model in all_deep_models:\n",
        "    model_name = deep_model\n",
        "    model_name_txt = str(all_model_name_txt[i])\n",
        "    # Load the fully-connected Layer (FCL)\n",
        "    MODEL_FILE = \"./Results/\"+str(dataset_version)+\"/\"+str(model_name_txt)+\"/\"+\"30epochs\"+\"/\"+str(model_name_txt)+\"_stage2_FCL.model\"\n",
        "    model_2 = load_model(MODEL_FILE)\n",
        "    model_2.summary()\n",
        "    i+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for testing\n",
        "########################## Test FCL: 30epochs ##############################\n",
        "\n",
        "#import seaborn as sn\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "# Do the prediction\n",
        "predictions = model_2.predict(X_test_global_descriptor) # predict the classe of the test images\n",
        "(samples, classes)= predictions.shape\n",
        "\n",
        "# Extract the index of prediction from the preds_scores_matrix\n",
        "y_pred= np.zeros_like(y_test_global_descriptor)\n",
        "y_pred_classes= np.empty(len(y_test_global_descriptor), dtype=object)\n",
        "\n",
        "for i in range(samples):\n",
        "   preds_scores_matrix = predictions[i, :]\n",
        "   idx, label, propability = getPrediction(preds_scores_matrix)\n",
        "   y_pred[i]= idx\n",
        "   y_pred_classes[i] = label\n",
        "\n",
        "\n",
        "\n",
        "# return the predicted classe of the test images as labels such as \"airplane\n",
        "y_true_classes = np.empty(len(y_test_global_descriptor), dtype=object)\n",
        "\n",
        "for t in range (len(y_test_global_descriptor)):\n",
        "   y_true_classes[t] = class_info[y_test_global_descriptor[t]]\n",
        "\n",
        "\n",
        "#Confution Matrix and Classification Report\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(y_true_classes, y_pred_classes))\n",
        "\n",
        "print('Classification Report')\n",
        "#####  I may remove the class number from the target_names\n",
        "target_names = ['airplane', 'bathtub', 'bed', 'bench', 'bookshelf', 'bottle', 'bowl', 'car', 'chair', 'cone',\n",
        "                'cup', 'curtain', 'desk', 'door', 'dresser', 'flower_pot', 'glass_box', 'guitar', 'keyboard', 'lamp',\n",
        "                'laptop', 'mantel', 'monitor', 'night_stand', 'person', 'piano', 'plant', 'radio', 'range_hood', 'sink',\n",
        "                'sofa', 'stairs','stool', 'table', 'tent', 'toilet', 'tv_stand', 'vase', 'wardrobe', 'xbox']\n",
        "\n",
        "print(classification_report(y_true_classes, y_pred_classes, target_names=target_names))\n",
        "print (\"--- y_true_classes\")\n",
        "print (y_true_classes)\n",
        "print (\"--- y_pred_classes\")\n",
        "print (y_pred_classes)\n",
        "ccm = confusion_matrix(y_true_classes, y_pred_classes) # Create ConfusionMatrix From Data\n",
        "\n",
        "results = \"./Results/\"+str(dataset_version)+\"/\"+str(model_name_txt)+\"/\"+str(model_name_txt)+\"_30epochs_FCL_Results.txt\"\n",
        "f = open(results, \"w\")\n",
        "cm = ConfusionMatrix(actual_vector=y_true_classes, predict_vector=y_pred_classes) # Create ConfusionMatrix From categorical Data\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=ccm, display_labels=target_names)\n",
        "disp.plot(cmap=plt.cm.Blues, xticks_rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"./Results/\"+str(dataset_version)+\"/\"+str(model_name_txt)+\"/\"+\"30epochs_FCL_ConfusionMatrix.png\", pad_inches=5)\n",
        "plt.tick_params(axis='both', which='major', labelsize=5)\n",
        "plt.show()\n",
        "\n",
        "f.write(\"{}\\n\".format(cm))\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.99      1.00      1.00       100\n",
            "     bathtub       0.92      0.68      0.78        50\n",
            "         bed       0.88      0.92      0.90       100\n",
            "       bench       0.57      0.85      0.68        20\n",
            "   bookshelf       0.85      0.84      0.84       100\n",
            "      bottle       0.90      0.95      0.93       100\n",
            "        bowl       0.81      0.85      0.83        20\n",
            "         car       0.98      0.99      0.99       100\n",
            "       chair       0.86      0.92      0.89       100\n",
            "        cone       0.90      0.95      0.93        20\n",
            "         cup       0.61      0.55      0.58        20\n",
            "     curtain       0.86      0.90      0.88        20\n",
            "        desk       0.75      0.72      0.73        86\n",
            "        door       0.83      0.95      0.88        20\n",
            "     dresser       0.87      0.87      0.87        86\n",
            "  flower_pot       0.34      0.60      0.44        20\n",
            "   glass_box       0.81      0.76      0.78       100\n",
            "      guitar       0.98      0.98      0.98       100\n",
            "    keyboard       0.95      1.00      0.98        20\n",
            "        lamp       0.74      0.70      0.72        20\n",
            "      laptop       0.66      0.95      0.78        20\n",
            "      mantel       0.86      0.87      0.87       100\n",
            "     monitor       0.87      0.93      0.90       100\n",
            " night_stand       0.76      0.67      0.72        86\n",
            "      person       1.00      0.95      0.97        20\n",
            "       piano       0.85      0.72      0.78       100\n",
            "       plant       0.94      0.83      0.88       100\n",
            "       radio       0.52      0.55      0.54        20\n",
            "  range_hood       0.93      0.80      0.86       100\n",
            "        sink       0.40      0.60      0.48        20\n",
            "        sofa       0.87      0.96      0.91       100\n",
            "      stairs       0.72      0.65      0.68        20\n",
            "       stool       0.67      0.60      0.63        20\n",
            "       table       0.83      0.76      0.79       100\n",
            "        tent       0.48      0.70      0.57        20\n",
            "      toilet       0.90      0.95      0.92       100\n",
            "    tv_stand       0.74      0.70      0.72       100\n",
            "        vase       0.85      0.80      0.82       100\n",
            "    wardrobe       0.60      0.60      0.60        20\n",
            "        xbox       0.71      0.60      0.65        20\n",
            "\n",
            "    accuracy                           0.84      2468\n",
            "   macro avg       0.79      0.80      0.79      2468\n",
            "weighted avg       0.85      0.84      0.84      2468\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_true_classes, y_pred_classes, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Accuracy:\n",
            "airplane = 0.99\n",
            "bathtub = 0.8\n",
            "bed = 0.95\n",
            "bench = 0.55\n",
            "bookshelf = 0.93\n",
            "bottle = 0.65\n",
            "bowl = 0.6\n",
            "car = 0.68\n",
            "chair = 0.98\n",
            "cone = 0.76\n",
            "cup = 0.6\n",
            "curtain = 0.96\n",
            "desk = 0.6\n",
            "door = 0.6\n",
            "dresser = 0.72\n",
            "flower_pot = 0.7209302325581395\n",
            "glass_box = 0.9\n",
            "guitar = 0.7\n",
            "keyboard = 0.85\n",
            "lamp = 0.55\n",
            "laptop = 0.92\n",
            "mantel = 0.8\n",
            "monitor = 0.95\n",
            "night_stand = 0.87\n",
            "person = 0.95\n",
            "piano = 0.95\n",
            "plant = 0.76\n",
            "radio = 0.83\n",
            "range_hood = 0.92\n",
            "sink = 1.0\n",
            "sofa = 1.0\n",
            "stairs = 0.6\n",
            "stool = 0.84\n",
            "table = 0.6744186046511628\n",
            "tent = 0.7\n",
            "toilet = 0.95\n",
            "tv_stand = 0.85\n",
            "vase = 0.872093023255814\n",
            "wardrobe = 0.95\n",
            "xbox = 0.7\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "Overall Accuracy: 83.79254457050244 %\n",
            "Average Accuracy: 80.44360465116279 %\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Obtain the true labels and predicted labels\n",
        "true_labels = y_true_classes  # Replace with your true labels\n",
        "predicted_labels = y_pred_classes # Replace with your predicted labels\n",
        "\n",
        "# Calculate overall accuracy\n",
        "overall_accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "\n",
        "# Calculate average accuracy\n",
        "class_labels = set(true_labels)  # Get the unique class labels\n",
        "num_classes = len(class_labels)\n",
        "class_accuracies = []\n",
        "\n",
        "for label in class_labels:\n",
        "    # Filter the true and predicted labels corresponding to the current class\n",
        "    true_labels_class = [true_labels[i] for i in range(len(true_labels)) if true_labels[i] == label]\n",
        "    predicted_labels_class = [predicted_labels[i] for i in range(len(predicted_labels)) if true_labels[i] == label]\n",
        "    \n",
        "    # Calculate accuracy for the current class\n",
        "    class_accuracy = accuracy_score(true_labels_class, predicted_labels_class)\n",
        "    class_accuracies.append(class_accuracy)\n",
        "\n",
        "average_accuracy = sum(class_accuracies) / num_classes\n",
        "\n",
        "# Print overall accuracy and average accuracy\n",
        "print(\"Class Accuracy:\")\n",
        "for i in range(40):\n",
        "    print(target_names[i], \"=\", class_accuracies[i])\n",
        "print(\"------------------------------------------\")\n",
        "print(\"------------------------------------------\")\n",
        "print(\"------------------------------------------\")\n",
        "print(\"Overall Accuracy:\", overall_accuracy*100, \"%\")\n",
        "print(\"Average Accuracy:\", average_accuracy*100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test FCN: 20epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 1024)              102761472 \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 40)                41000     \n",
            "=================================================================\n",
            "Total params: 102,802,472\n",
            "Trainable params: 102,802,472\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# for testing\n",
        "########################## Load FCN: 20epochs ##############################\n",
        "\n",
        "i=0\n",
        "for deep_model in all_deep_models:\n",
        "    model_name = deep_model\n",
        "    model_name_txt = str(all_model_name_txt[i])\n",
        "    # Load the fully-connected network (FCN)\n",
        "    MODEL_FILE = \"./Results/\"+str(dataset_version)+\"/\"+str(model_name_txt)+\"/\"+\"20epochs\"+\"/\"+str(model_name_txt)+\"_stage2_FCN.model\"\n",
        "    model_2 = load_model(MODEL_FILE)\n",
        "    model_2.summary()\n",
        "    i+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for testing\n",
        "########################## Test FCN: 20epochs ##############################\n",
        "\n",
        "#import seaborn as sn\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "# Do the prediction\n",
        "predictions = model_2.predict(X_test_global_descriptor) # predict the classe of the test images\n",
        "(samples, classes)= predictions.shape\n",
        "\n",
        "# Extract the index of prediction from the preds_scores_matrix\n",
        "y_pred= np.zeros_like(y_test_global_descriptor)\n",
        "y_pred_classes= np.empty(len(y_test_global_descriptor), dtype=object)\n",
        "\n",
        "for i in range(samples):\n",
        "   preds_scores_matrix = predictions[i, :]\n",
        "   idx, label, propability = getPrediction(preds_scores_matrix)\n",
        "   y_pred[i]= idx\n",
        "   y_pred_classes[i] = label\n",
        "\n",
        "\n",
        "\n",
        "# return the predicted classe of the test images as labels such as \"airplane\n",
        "y_true_classes = np.empty(len(y_test_global_descriptor), dtype=object)\n",
        "\n",
        "for t in range (len(y_test_global_descriptor)):\n",
        "   y_true_classes[t] = class_info[y_test_global_descriptor[t]]\n",
        " \n",
        "#Confution Matrix and Classification Report\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(y_true_classes, y_pred_classes))\n",
        "#tn, fp, fn, tp = confusion_matrix(y_true_classes, y_pred_classes).ravel()\n",
        "\n",
        "\n",
        "\n",
        "print('Classification Report')\n",
        "target_names = ['airplane', 'bathtub', 'bed', 'bench', 'bookshelf', 'bottle', 'bowl', 'car', 'chair', 'cone',\n",
        "                'cup', 'curtain', 'desk', 'door', 'dresser', 'flower_pot', 'glass_box', 'guitar', 'keyboard', 'lamp',\n",
        "                'laptop', 'mantel', 'monitor', 'night_stand', 'person', 'piano', 'plant', 'radio', 'range_hood', 'sink',\n",
        "                'sofa', 'stairs','stool', 'table', 'tent', 'toilet', 'tv_stand', 'vase', 'wardrobe', 'xbox']\n",
        "\n",
        "print(classification_report(y_true_classes, y_pred_classes, target_names=target_names))\n",
        "print (\"--- y_true_classes\")\n",
        "print (y_true_classes)\n",
        "print (\"--- y_pred_classes\")\n",
        "print (y_pred_classes)\n",
        "ccm = confusion_matrix(y_true_classes, y_pred_classes) # Create ConfusionMatrix From Data\n",
        "\n",
        "results = \"./Results/\"+str(dataset_version)+\"/\"+str(model_name_txt)+\"/\"+str(model_name_txt)+\"_20epochs_FCN_Results.txt\"\n",
        "f = open(results, \"w\")\n",
        "cm = ConfusionMatrix(actual_vector=y_true_classes, predict_vector=y_pred_classes) # Create ConfusionMatrix From categorical Data\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=ccm, display_labels=target_names)\n",
        "disp.plot(cmap=plt.cm.Blues, xticks_rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"./Results/\"+str(dataset_version)+\"/\"+str(model_name_txt)+\"/\"+\"20epochs_FCN_ConfusionMatrix.png\", pad_inches=5)\n",
        "plt.tick_params(axis='both', which='major', labelsize=5)\n",
        "plt.show()\n",
        "\n",
        "f.write(\"{}\\n\".format(cm))\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.98      1.00      0.99       100\n",
            "     bathtub       0.75      0.36      0.49        50\n",
            "         bed       0.72      0.91      0.81       100\n",
            "       bench       0.58      0.70      0.64        20\n",
            "   bookshelf       0.70      0.86      0.77       100\n",
            "      bottle       0.92      0.96      0.94       100\n",
            "        bowl       0.81      0.85      0.83        20\n",
            "         car       0.98      0.95      0.96       100\n",
            "       chair       0.70      0.92      0.80       100\n",
            "        cone       0.95      0.95      0.95        20\n",
            "         cup       0.61      0.55      0.58        20\n",
            "     curtain       0.89      0.80      0.84        20\n",
            "        desk       0.65      0.60      0.63        86\n",
            "        door       0.79      0.75      0.77        20\n",
            "     dresser       0.68      0.76      0.72        86\n",
            "  flower_pot       0.31      0.55      0.40        20\n",
            "   glass_box       0.69      0.75      0.72       100\n",
            "      guitar       0.99      1.00      1.00       100\n",
            "    keyboard       0.90      0.95      0.93        20\n",
            "        lamp       0.86      0.60      0.71        20\n",
            "      laptop       0.42      0.70      0.53        20\n",
            "      mantel       0.67      0.78      0.72       100\n",
            "     monitor       0.84      0.93      0.88       100\n",
            " night_stand       0.61      0.53      0.57        86\n",
            "      person       1.00      0.85      0.92        20\n",
            "       piano       0.86      0.61      0.71       100\n",
            "       plant       0.93      0.80      0.86       100\n",
            "       radio       0.33      0.15      0.21        20\n",
            "  range_hood       0.95      0.63      0.76       100\n",
            "        sink       0.50      0.55      0.52        20\n",
            "        sofa       0.69      0.94      0.79       100\n",
            "      stairs       0.75      0.45      0.56        20\n",
            "       stool       0.79      0.55      0.65        20\n",
            "       table       0.84      0.67      0.74       100\n",
            "        tent       0.44      0.55      0.49        20\n",
            "      toilet       0.84      0.97      0.90       100\n",
            "    tv_stand       0.65      0.51      0.57       100\n",
            "        vase       0.79      0.78      0.78       100\n",
            "    wardrobe       0.25      0.05      0.08        20\n",
            "        xbox       0.64      0.45      0.53        20\n",
            "\n",
            "    accuracy                           0.77      2468\n",
            "   macro avg       0.73      0.71      0.71      2468\n",
            "weighted avg       0.78      0.77      0.76      2468\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_true_classes, y_pred_classes, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Accuracy:\n",
            "airplane = 0.95\n",
            "bathtub = 0.63\n",
            "bed = 0.97\n",
            "bench = 0.55\n",
            "bookshelf = 0.93\n",
            "bottle = 0.45\n",
            "bowl = 0.55\n",
            "car = 0.36\n",
            "chair = 1.0\n",
            "cone = 0.75\n",
            "cup = 0.45\n",
            "curtain = 0.94\n",
            "desk = 0.05\n",
            "door = 0.55\n",
            "dresser = 0.61\n",
            "flower_pot = 0.6046511627906976\n",
            "glass_box = 0.8\n",
            "guitar = 0.6\n",
            "keyboard = 0.85\n",
            "lamp = 0.15\n",
            "laptop = 0.92\n",
            "mantel = 0.78\n",
            "monitor = 0.7\n",
            "night_stand = 0.78\n",
            "person = 0.85\n",
            "piano = 0.96\n",
            "plant = 0.67\n",
            "radio = 0.8\n",
            "range_hood = 0.91\n",
            "sink = 1.0\n",
            "sofa = 0.95\n",
            "stairs = 0.55\n",
            "stool = 0.86\n",
            "table = 0.5348837209302325\n",
            "tent = 0.51\n",
            "toilet = 0.75\n",
            "tv_stand = 0.7\n",
            "vase = 0.7558139534883721\n",
            "wardrobe = 0.95\n",
            "xbox = 0.55\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "Overall Accuracy: 76.90437601296597 %\n",
            "Average Accuracy: 70.56337209302326 %\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Obtain the true labels and predicted labels\n",
        "true_labels = y_true_classes  # Replace with your true labels\n",
        "predicted_labels = y_pred_classes # Replace with your predicted labels\n",
        "\n",
        "# Calculate overall accuracy\n",
        "overall_accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "\n",
        "# Calculate average accuracy\n",
        "class_labels = set(true_labels)  # Get the unique class labels\n",
        "num_classes = len(class_labels)\n",
        "class_accuracies = []\n",
        "\n",
        "for label in class_labels:\n",
        "    # Filter the true and predicted labels corresponding to the current class\n",
        "    true_labels_class = [true_labels[i] for i in range(len(true_labels)) if true_labels[i] == label]\n",
        "    predicted_labels_class = [predicted_labels[i] for i in range(len(predicted_labels)) if true_labels[i] == label]\n",
        "    \n",
        "    # Calculate accuracy for the current class\n",
        "    class_accuracy = accuracy_score(true_labels_class, predicted_labels_class)\n",
        "    class_accuracies.append(class_accuracy)\n",
        "\n",
        "average_accuracy = sum(class_accuracies) / num_classes\n",
        "\n",
        "# Print overall accuracy and average accuracy\n",
        "print(\"Class Accuracy:\")\n",
        "for i in range(40):\n",
        "    print(target_names[i], \"=\", class_accuracies[i])\n",
        "print(\"------------------------------------------\")\n",
        "print(\"------------------------------------------\")\n",
        "print(\"------------------------------------------\")\n",
        "print(\"Overall Accuracy:\", overall_accuracy*100, \"%\")\n",
        "print(\"Average Accuracy:\", average_accuracy*100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test FCN: 30epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 1024)              102761472 \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 40)                41000     \n",
            "=================================================================\n",
            "Total params: 102,802,472\n",
            "Trainable params: 102,802,472\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# for testing\n",
        "########################## Load FCN: 30epochs ##############################\n",
        "\n",
        "i=0\n",
        "for deep_model in all_deep_models:\n",
        "    model_name = deep_model\n",
        "    model_name_txt = str(all_model_name_txt[i])\n",
        "    # Load the fully-connected network (FCN)\n",
        "    MODEL_FILE = \"./Results/\"+str(dataset_version)+\"/\"+str(model_name_txt)+\"/\"+\"30epochs\"+\"/\"+str(model_name_txt)+\"_stage2_FCN.model\"\n",
        "    model_2 = load_model(MODEL_FILE)\n",
        "    model_2.summary()\n",
        "    i+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for testing\n",
        "########################## Test FCN: 30epochs ##############################\n",
        "\n",
        "#import seaborn as sn\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "# Do the prediction\n",
        "predictions = model_2.predict(X_test_global_descriptor) # predict the classe of the test images\n",
        "(samples, classes)= predictions.shape\n",
        "\n",
        "# Extract the index of prediction from the preds_scores_matrix\n",
        "y_pred= np.zeros_like(y_test_global_descriptor)\n",
        "y_pred_classes= np.empty(len(y_test_global_descriptor), dtype=object)\n",
        "\n",
        "for i in range(samples):\n",
        "   preds_scores_matrix = predictions[i, :]\n",
        "   idx, label, propability = getPrediction(preds_scores_matrix)\n",
        "   y_pred[i]= idx\n",
        "   y_pred_classes[i] = label\n",
        "\n",
        "\n",
        "\n",
        "# return the predicted classe of the test images as labels such as \"airplane\n",
        "y_true_classes = np.empty(len(y_test_global_descriptor), dtype=object)\n",
        "\n",
        "for t in range (len(y_test_global_descriptor)):\n",
        "   y_true_classes[t] = class_info[y_test_global_descriptor[t]]\n",
        "\n",
        "\n",
        "#Confution Matrix and Classification Report\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(y_true_classes, y_pred_classes))\n",
        "#tn, fp, fn, tp = confusion_matrix(y_true_classes, y_pred_classes).ravel()\n",
        "\n",
        "\n",
        "\n",
        "print('Classification Report')\n",
        "#####  I may remove the class number from the target_names\n",
        "target_names = ['airplane', 'bathtub', 'bed', 'bench', 'bookshelf', 'bottle', 'bowl', 'car', 'chair', 'cone',\n",
        "                'cup', 'curtain', 'desk', 'door', 'dresser', 'flower_pot', 'glass_box', 'guitar', 'keyboard', 'lamp',\n",
        "                'laptop', 'mantel', 'monitor', 'night_stand', 'person', 'piano', 'plant', 'radio', 'range_hood', 'sink',\n",
        "                'sofa', 'stairs','stool', 'table', 'tent', 'toilet', 'tv_stand', 'vase', 'wardrobe', 'xbox']\n",
        "\n",
        "print(classification_report(y_true_classes, y_pred_classes, target_names=target_names))\n",
        "print (\"--- y_true_classes\")\n",
        "print (y_true_classes)\n",
        "print (\"--- y_pred_classes\")\n",
        "print (y_pred_classes)\n",
        "ccm = confusion_matrix(y_true_classes, y_pred_classes) # Create ConfusionMatrix From Data\n",
        "\n",
        "results = \"./Results/\"+str(dataset_version)+\"/\"+str(model_name_txt)+\"/\"+str(model_name_txt)+\"_30epochs_FCN_Results.txt\"\n",
        "f = open(results, \"w\")\n",
        "cm = ConfusionMatrix(actual_vector=y_true_classes, predict_vector=y_pred_classes) # Create ConfusionMatrix From categorical Data\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=ccm, display_labels=target_names)\n",
        "disp.plot(cmap=plt.cm.Blues, xticks_rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"./Results/\"+str(dataset_version)+\"/\"+str(model_name_txt)+\"/\"+\"30epochs_FCN_ConfusionMatrix.png\", pad_inches=5)\n",
        "plt.tick_params(axis='both', which='major', labelsize=5)\n",
        "plt.show()\n",
        "\n",
        "f.write(\"{}\\n\".format(cm))\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.99      1.00      1.00       100\n",
            "     bathtub       0.83      0.48      0.61        50\n",
            "         bed       0.80      0.93      0.86       100\n",
            "       bench       0.71      0.75      0.73        20\n",
            "   bookshelf       0.74      0.87      0.80       100\n",
            "      bottle       0.92      0.97      0.95       100\n",
            "        bowl       0.74      0.85      0.79        20\n",
            "         car       0.97      0.99      0.98       100\n",
            "       chair       0.79      0.92      0.85       100\n",
            "        cone       1.00      1.00      1.00        20\n",
            "         cup       0.63      0.60      0.62        20\n",
            "     curtain       0.86      0.90      0.88        20\n",
            "        desk       0.69      0.69      0.69        86\n",
            "        door       0.86      0.95      0.90        20\n",
            "     dresser       0.77      0.77      0.77        86\n",
            "  flower_pot       0.31      0.55      0.39        20\n",
            "   glass_box       0.76      0.76      0.76       100\n",
            "      guitar       1.00      1.00      1.00       100\n",
            "    keyboard       0.95      1.00      0.98        20\n",
            "        lamp       0.87      0.65      0.74        20\n",
            "      laptop       0.61      0.85      0.71        20\n",
            "      mantel       0.72      0.81      0.76       100\n",
            "     monitor       0.87      0.93      0.90       100\n",
            " night_stand       0.68      0.60      0.64        86\n",
            "      person       1.00      1.00      1.00        20\n",
            "       piano       0.90      0.73      0.81       100\n",
            "       plant       0.93      0.81      0.87       100\n",
            "       radio       0.46      0.30      0.36        20\n",
            "  range_hood       0.99      0.70      0.82       100\n",
            "        sink       0.52      0.65      0.58        20\n",
            "        sofa       0.77      0.95      0.85       100\n",
            "      stairs       0.77      0.50      0.61        20\n",
            "       stool       0.72      0.65      0.68        20\n",
            "       table       0.87      0.75      0.81       100\n",
            "        tent       0.42      0.65      0.51        20\n",
            "      toilet       0.88      0.98      0.92       100\n",
            "    tv_stand       0.67      0.61      0.64       100\n",
            "        vase       0.83      0.77      0.80       100\n",
            "    wardrobe       0.38      0.15      0.21        20\n",
            "        xbox       0.69      0.55      0.61        20\n",
            "\n",
            "    accuracy                           0.81      2468\n",
            "   macro avg       0.77      0.76      0.76      2468\n",
            "weighted avg       0.82      0.81      0.81      2468\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_true_classes, y_pred_classes, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Accuracy:\n",
            "airplane = 0.99\n",
            "bathtub = 0.7\n",
            "bed = 0.98\n",
            "bench = 0.6\n",
            "bookshelf = 0.93\n",
            "bottle = 0.5\n",
            "bowl = 0.65\n",
            "car = 0.48\n",
            "chair = 1.0\n",
            "cone = 0.76\n",
            "cup = 0.55\n",
            "curtain = 0.95\n",
            "desk = 0.15\n",
            "door = 0.55\n",
            "dresser = 0.73\n",
            "flower_pot = 0.686046511627907\n",
            "glass_box = 0.9\n",
            "guitar = 0.65\n",
            "keyboard = 0.85\n",
            "lamp = 0.3\n",
            "laptop = 0.92\n",
            "mantel = 0.77\n",
            "monitor = 0.85\n",
            "night_stand = 0.81\n",
            "person = 1.0\n",
            "piano = 0.97\n",
            "plant = 0.75\n",
            "radio = 0.81\n",
            "range_hood = 0.93\n",
            "sink = 1.0\n",
            "sofa = 1.0\n",
            "stairs = 0.65\n",
            "stool = 0.87\n",
            "table = 0.6046511627906976\n",
            "tent = 0.61\n",
            "toilet = 0.95\n",
            "tv_stand = 0.75\n",
            "vase = 0.7674418604651163\n",
            "wardrobe = 1.0\n",
            "xbox = 0.65\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "Overall Accuracy: 81.03727714748784 %\n",
            "Average Accuracy: 76.42034883720929 %\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Obtain the true labels and predicted labels\n",
        "true_labels = y_true_classes  # Replace with your true labels\n",
        "predicted_labels = y_pred_classes # Replace with your predicted labels\n",
        "\n",
        "# Calculate overall accuracy\n",
        "overall_accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "\n",
        "# Calculate average accuracy\n",
        "class_labels = set(true_labels)  # Get the unique class labels\n",
        "num_classes = len(class_labels)\n",
        "class_accuracies = []\n",
        "\n",
        "for label in class_labels:\n",
        "    # Filter the true and predicted labels corresponding to the current class\n",
        "    true_labels_class = [true_labels[i] for i in range(len(true_labels)) if true_labels[i] == label]\n",
        "    predicted_labels_class = [predicted_labels[i] for i in range(len(predicted_labels)) if true_labels[i] == label]\n",
        "    \n",
        "    # Calculate accuracy for the current class\n",
        "    class_accuracy = accuracy_score(true_labels_class, predicted_labels_class)\n",
        "    class_accuracies.append(class_accuracy)\n",
        "\n",
        "average_accuracy = sum(class_accuracies) / num_classes\n",
        "\n",
        "# Print overall accuracy and average accuracy\n",
        "print(\"Class Accuracy:\")\n",
        "for i in range(40):\n",
        "    print(target_names[i], \"=\", class_accuracies[i])\n",
        "print(\"------------------------------------------\")\n",
        "print(\"------------------------------------------\")\n",
        "print(\"------------------------------------------\")\n",
        "print(\"Overall Accuracy:\", overall_accuracy*100, \"%\")\n",
        "print(\"Average Accuracy:\", average_accuracy*100, \"%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02b023d69193415998e8b4a6bfd28160": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0af475302c11460e9721ad21551d4f30": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c77d35ea40e4f3a92a60f1a9fad5269": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39fa904a61fb4c4d966c81d2edc774a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3be50e75aaba43e7b5a425607054fff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ebe05ab17934d0ab1a9a2d7464391fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39fa904a61fb4c4d966c81d2edc774a5",
            "placeholder": "​",
            "style": "IPY_MODEL_02b023d69193415998e8b4a6bfd28160",
            "value": "100%"
          }
        },
        "7b34fdf21660443e902ed7fc444ba2f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dabf6db73558436c905e53496f1b9673",
              "IPY_MODEL_a2823c4b78364a1e8708a0256537acb2",
              "IPY_MODEL_f3eb463870eb465489e26d3e3c8a714a"
            ],
            "layout": "IPY_MODEL_a5eb3ad1824a47f9bc7ea5507153520b"
          }
        },
        "7c40a56ee49e4aaba1a21b7b1da95964": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d4c69bdcdc542d9b4850025b651e103": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ec3d3a057594e3599368801af2fd9cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa6e024f8fb84361b4640ed5a6995c39",
            "placeholder": "​",
            "style": "IPY_MODEL_eb79ecf46c03469cb3c4808e285c3d3f",
            "value": " 480/480 [00:00&lt;00:00, 9375.76it/s]"
          }
        },
        "86caae72e09a40b79aba013ca3402c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2823c4b78364a1e8708a0256537acb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d4c69bdcdc542d9b4850025b651e103",
            "max": 40,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86caae72e09a40b79aba013ca3402c14",
            "value": 40
          }
        },
        "a5eb3ad1824a47f9bc7ea5507153520b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa6e024f8fb84361b4640ed5a6995c39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad37ff0c3f87445787c986ec50dd9638": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c77d35ea40e4f3a92a60f1a9fad5269",
            "max": 480,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3be50e75aaba43e7b5a425607054fff7",
            "value": 480
          }
        },
        "c96de45b9dab4d5ba333926c73855ba4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d18938a4c231481a977b3dc73f175372": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4ad3d4b91464ce981f9b6165f3bd34d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dabf6db73558436c905e53496f1b9673": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0af475302c11460e9721ad21551d4f30",
            "placeholder": "​",
            "style": "IPY_MODEL_7c40a56ee49e4aaba1a21b7b1da95964",
            "value": "100%"
          }
        },
        "eb79ecf46c03469cb3c4808e285c3d3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f227cfded2114c18a1b3f891e3e762f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ebe05ab17934d0ab1a9a2d7464391fd",
              "IPY_MODEL_ad37ff0c3f87445787c986ec50dd9638",
              "IPY_MODEL_7ec3d3a057594e3599368801af2fd9cc"
            ],
            "layout": "IPY_MODEL_d4ad3d4b91464ce981f9b6165f3bd34d"
          }
        },
        "f3eb463870eb465489e26d3e3c8a714a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c96de45b9dab4d5ba333926c73855ba4",
            "placeholder": "​",
            "style": "IPY_MODEL_d18938a4c231481a977b3dc73f175372",
            "value": " 40/40 [00:00&lt;00:00, 1146.21it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
